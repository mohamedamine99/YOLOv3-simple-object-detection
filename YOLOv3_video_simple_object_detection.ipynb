{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "<div align=\"center\">\n",
        "\n",
        "# YOLOv3 simple object detection on video files\n",
        "</div>\n",
        "\n",
        "YOLOv3 (You Only Look Once v3) is a state-of-the-art object detection algorithm that is widely used in computer vision applications. It is known for its fast inference speed and high accuracy in detecting multiple objects in a video. In this Jupyter notebook, we will implement a YOLOv3 object detection algorithm on a set of test images using Python and OpenCV library. We will use pre-trained weights and configurations for YOLOv3 and YOLOv3-tiny models to detect objects in video frames and draw bounding boxes around them with corresponding labels.\n"
      ],
      "metadata": {
        "id": "VfC-T3YR94wF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Downloading pretrained models and test files"
      ],
      "metadata": {
        "id": "4Vb7qNVZ-KmW"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZwL6lHJabill",
        "outputId": "ddc1536e-7ba0-4ecd-9244-4cdfdfde9767"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'darknet'...\n",
            "remote: Enumerating objects: 5955, done.\u001b[K\n",
            "remote: Total 5955 (delta 0), reused 0 (delta 0), pack-reused 5955\u001b[K\n",
            "Receiving objects: 100% (5955/5955), 6.37 MiB | 21.19 MiB/s, done.\n",
            "Resolving deltas: 100% (3932/3932), done.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/pjreddie/darknet"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/mohamedamine99/YOLOv3-simple-object-detection"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CfDqJROcbrJb",
        "outputId": "bf230f28-8e01-4e1a-fc57-4fe1c95aa549"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'YOLOv3-simple-object-detection'...\n",
            "remote: Enumerating objects: 82, done.\u001b[K\n",
            "remote: Counting objects: 100% (82/82), done.\u001b[K\n",
            "remote: Compressing objects: 100% (67/67), done.\u001b[K\n",
            "remote: Total 82 (delta 22), reused 69 (delta 12), pack-reused 0\u001b[K\n",
            "Unpacking objects: 100% (82/82), 38.87 MiB | 9.79 MiB/s, done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://pjreddie.com/media/files/yolov3-tiny.weights"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4fGHcv2jgUyP",
        "outputId": "8d7d77fb-05a8-4b08-f2c1-f0d51d8a5f25"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2023-03-12 12:52:44--  https://pjreddie.com/media/files/yolov3-tiny.weights\n",
            "Resolving pjreddie.com (pjreddie.com)... 128.208.4.108\n",
            "Connecting to pjreddie.com (pjreddie.com)|128.208.4.108|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 35434956 (34M) [application/octet-stream]\n",
            "Saving to: ‘yolov3-tiny.weights’\n",
            "\n",
            "yolov3-tiny.weights 100%[===================>]  33.79M  26.3MB/s    in 1.3s    \n",
            "\n",
            "2023-03-12 12:52:46 (26.3 MB/s) - ‘yolov3-tiny.weights’ saved [35434956/35434956]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://pjreddie.com/media/files/yolov3.weights"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kuc9pr7KgeKF",
        "outputId": "741447eb-8b2c-4a27-e90a-b8b40fc54787"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2023-03-12 12:52:46--  https://pjreddie.com/media/files/yolov3.weights\n",
            "Resolving pjreddie.com (pjreddie.com)... 128.208.4.108\n",
            "Connecting to pjreddie.com (pjreddie.com)|128.208.4.108|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 248007048 (237M) [application/octet-stream]\n",
            "Saving to: ‘yolov3.weights’\n",
            "\n",
            "yolov3.weights      100%[===================>] 236.52M  39.1MB/s    in 6.5s    \n",
            "\n",
            "2023-03-12 12:52:53 (36.3 MB/s) - ‘yolov3.weights’ saved [248007048/248007048]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## YOLOv3 implementation"
      ],
      "metadata": {
        "id": "Olsu-Ti--VkL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import shutil\n",
        "import time\n",
        "\n",
        "import numpy as np\n",
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "import imageio"
      ],
      "metadata": {
        "id": "UwzJBdY7cKsZ"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Paths for various files and directories\n",
        "coco_names_file = '/content/YOLOv3-simple-object-detection/coco.names'\n",
        "\n",
        "yolov3_cfg = '/content/YOLOv3-simple-object-detection/configs/yolov3.cfg'\n",
        "yolov3_tiny_cfg = '/content/YOLOv3-simple-object-detection/configs/yolov3-tiny.cfg'\n",
        "\n",
        "yolov3_weights = '/content/yolov3.weights'\n",
        "yolov3_tiny_weights = '/content/yolov3-tiny.weights'\n",
        "\n",
        "test_vids_path = '/content/YOLOv3-simple-object-detection/test vids'\n",
        "results_yolov3 = '/content/results/YOLOv3'\n",
        "results_yolov3_tiny = '/content/results/YOLOv3_tiny'"
      ],
      "metadata": {
        "id": "GgATss7bcVjf"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Reading the COCO dataset class names from the coco names file\n",
        "labels = []\n",
        "with open(coco_names_file, 'rt') as coco_file:\n",
        "    labels = coco_file.read().rstrip('\\n').rsplit('\\n')\n",
        "    \n",
        "print(labels)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FS1lXT_lhUxn",
        "outputId": "9b10a353-eab2-42c0-bd46-16a6c544776f"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['person', 'bicycle', 'car', 'motorbike', 'aeroplane', 'bus', 'train', 'truck', 'boat', 'traffic light', 'fire hydrant', 'stop sign', 'parking meter', 'bench', 'bird', 'cat', 'dog', 'horse', 'sheep', 'cow', 'elephant', 'bear', 'zebra', 'giraffe', 'backpack', 'umbrella', 'handbag', 'tie', 'suitcase', 'frisbee', 'skis', 'snowboard', 'sports ball', 'kite', 'baseball bat', 'baseball glove', 'skateboard', 'surfboard', 'tennis racket', 'bottle', 'wine glass', 'cup', 'fork', 'knife', 'spoon', 'bowl', 'banana', 'apple', 'sandwich', 'orange', 'broccoli', 'carrot', 'hot dog', 'pizza', 'donut', 'cake', 'chair', 'sofa', 'pottedplant', 'bed', 'diningtable', 'toilet', 'tvmonitor', 'laptop', 'mouse', 'remote', 'keyboard', 'cell phone', 'microwave', 'oven', 'toaster', 'sink', 'refrigerator', 'book', 'clock', 'vase', 'scissors', 'teddy bear', 'hair drier', 'toothbrush']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Creating YOLOv3 DNN model from configuration and pre-trained weights\n",
        "net = cv2.dnn.readNetFromDarknet(yolov3_cfg, yolov3_weights)\n",
        "\n",
        "# Creating YOLOv3-tiny DNN model from configuration and pre-trained weights\n",
        "net_tiny = cv2.dnn.readNetFromDarknet(yolov3_tiny_cfg, yolov3_tiny_weights)"
      ],
      "metadata": {
        "id": "l4wvVEPJijm5"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocess_img_for_detection(net, img, size = (320, 320)):\n",
        "    \"\"\"\n",
        "    This function preprocesses an input image for object detection using a specified YOLOv3 or YOLOv3-tiny\n",
        "    DNN model. The image is resized to the specified size and converted into a blob. The blob is then set\n",
        "    as the input for the DNN model. The function returns the output of the DNN model after forward pass.\n",
        "\n",
        "    Parameters:\n",
        "        net: cv2.dnn_Net object\n",
        "        YOLOv3 or YOLOv3-tiny DNN model.\n",
        "\n",
        "        img: numpy.ndarray\n",
        "        Input image for object detection.\n",
        "    \n",
        "        size: tuple, optional\n",
        "        Size to which the input image is resized. Default value is (320, 320).\n",
        "\n",
        "    Returns:\n",
        "        outputs: numpy.ndarray\n",
        "        Output of the DNN model after forward pass.\n",
        "    \n",
        "\n",
        "    \"\"\"\n",
        "    # Convert the input image into a blob\n",
        "    blob = cv2.dnn.blobFromImage(img, 1 / 255, size , [0, 0, 0], 1, crop=False)\n",
        "\n",
        "    # Set the blob as the input for the DNN model\n",
        "    net.setInput(blob)\n",
        "    layersNames = net.getLayerNames()\n",
        "\n",
        "    # Perform forward pass through the DNN model\n",
        "    output_layers_idx = net.getUnconnectedOutLayers()[0]-1\n",
        "    outputNames = [(layersNames[idx-1]) for idx in  net.getUnconnectedOutLayers()]\n",
        "    #print(outputNames)\n",
        "    outputs = net.forward(outputNames)\n",
        "\n",
        "    # Return the output of the DNN model after forward pass\n",
        "    return outputs\n"
      ],
      "metadata": {
        "id": "vUqhFPyPo0Ij"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def detectObjects(img, outputs, score_threshold = 0.8, NMS_threshold = 0.5 ):\n",
        "    \"\"\"\n",
        "    This function takes an input image and the output of a YOLOv3 or YOLOv3-tiny DNN model after forward pass,\n",
        "    detects objects in the image and draws bounding boxes around the objects. It also writes the class label and\n",
        "    confidence score for each object inside the bounding box.\n",
        "\n",
        "    Parameters:\n",
        "        img: numpy.ndarray\n",
        "        Input image for object detection.\n",
        "\n",
        "        outputs: numpy.ndarray\n",
        "        Output of the YOLOv3 or YOLOv3-tiny DNN model after forward pass.\n",
        "            \n",
        "        score_threshold: float, optional\n",
        "            Minimum confidence score required for an object to be considered for detection. Default value is 0.8.\n",
        "            \n",
        "        NMS_threshold: float, optional\n",
        "            Non-maximum suppression threshold for eliminating overlapping bounding boxes. Default value is 0.5.\n",
        "    \n",
        "        Returns:\n",
        "            img: numpy.ndarray\n",
        "            Input image with bounding boxes and class labels drawn around the detected objects.\n",
        "    \n",
        "    \"\"\"\n",
        "    # Get the shape of the input image\n",
        "    hT, wT, cT = img.shape\n",
        "\n",
        "    # Create empty lists to store the bounding boxes, class IDs and confidence scores for detected objects\n",
        "    bbox = []\n",
        "    classIds = []\n",
        "    confs = []\n",
        "\n",
        "    # Loop over each output of the DNN model after forward pass\n",
        "    for output in outputs:\n",
        "        # Loop over each detection in the output\n",
        "        for det in output:\n",
        "        # Extract the class ID, confidence score and bounding box coordinates from the detection\n",
        "            scores = det[5:]\n",
        "            classId = np.argmax(scores)\n",
        "            confidence = scores[classId]\n",
        "            if confidence > score_threshold:\n",
        "                w,h = int(det[2]*wT) , int(det[3]*hT)\n",
        "                x,y = int((det[0]*wT)-w/2) , int((det[1]*hT)-h/2)\n",
        "                bbox.append([x,y,w,h])\n",
        "                classIds.append(classId)\n",
        "                confs.append(float(confidence))\n",
        "\n",
        "    # Perform non-maximum suppression to eliminate overlapping bounding boxes\n",
        "    indices = cv2.dnn.NMSBoxes(bbox, confs, score_threshold, NMS_threshold)\n",
        "\n",
        "    # Loop over each index in the indices list\n",
        "    for i in indices :\n",
        "        # Get the bounding box coordinates, class label and confidence score for the current index\n",
        "        box = bbox[i]\n",
        "        x, y, w, h = box[0], box[1], box[2], box[3]\n",
        "        cv2.rectangle(img, (x, y), (x+w,y+h), (255, 0 , 255), 2)\n",
        "        cv2.putText(img,f'{labels[classIds[i]].upper()} {int(confs[i]*100)}%',\n",
        "                    (x, y-10), cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255, 0, 255), 2)\n",
        "        \n",
        "    #img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "    # Return the input image with bounding boxes and class labels drawn around the detected objects\n",
        "    return img\n",
        "\n",
        " "
      ],
      "metadata": {
        "id": "MqV6eAIDccaY"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Creating directories to store resulting images\n",
        "os.makedirs(results_yolov3) \n",
        "os.makedirs(results_yolov3_tiny) "
      ],
      "metadata": {
        "id": "cLvbnJShmLPv"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def detect_objects_in_videos_directory(net, videos_path, save_dir, size = (416, 416) , \n",
        "                                       score_threshold = 0.5, NMS_threshold = 0.4):\n",
        "    \n",
        "    \"\"\"\n",
        "    Detects objects in videos in the specified directory using the given model and saves the resulting video files\n",
        "    to the specified directory.\n",
        "    \n",
        "    Args:\n",
        "    - net: the neural network model to use for object detection\n",
        "    - videos_path: the path to the directory containing the videos to process\n",
        "    - save_dir: the path to the directory where the processed videos will be saved\n",
        "    - size: the size to resize the frames to before passing them to the neural network\n",
        "    - score_threshold: the confidence threshold below which detected objects will be discarded\n",
        "    - NMS_threshold: the Non-Maximum Suppression (NMS) threshold for removing overlapping bounding boxes\n",
        "    \n",
        "    Returns:\n",
        "    - None\n",
        "    \"\"\"\n",
        "    \n",
        "    for video_file in os.listdir(videos_path):\n",
        "        cap = cv2.VideoCapture(os.path.join(videos_path, video_file))\n",
        "\n",
        "        width  = int(cap.get(3) )  # get `width` \n",
        "        height = int(cap.get(4) )  # get `height` \n",
        "        print((width,height))\n",
        "        save_file = os.path.join(save_dir, video_file[:-4] + \".avi\")\n",
        "\n",
        "        # define an output VideoWriter  object\n",
        "        out = cv2.VideoWriter(save_file,\n",
        "                            cv2.VideoWriter_fourcc(*\"MJPG\"),\n",
        "                            20,(width,height))\n",
        "\n",
        "        # Check if the webcam is opened correctly\n",
        "        if not cap.isOpened():\n",
        "            print(\"Error opening video stream or file\")\n",
        "\n",
        "        # Read the video frames\n",
        "        while cap.isOpened():\n",
        "            ret, frame = cap.read()\n",
        "\n",
        "            # If the frame was not read successfully, break the loop\n",
        "            if not ret:\n",
        "                print(\"Error reading frame\")\n",
        "                print((width,height))\n",
        "                break\n",
        "            beg = time.time()\n",
        "\n",
        "            # Capture the video frame\n",
        "            # by frame\n",
        "            outputs = preprocess_img_for_detection(net, frame, size)\n",
        "\n",
        "            # Generate and then overlay the model heatmap for the current frame\n",
        "            frame = detectObjects(frame, outputs, score_threshold , NMS_threshold  )\n",
        "            #end = time.time()\n",
        "            #fps = 1/(end - beg)\n",
        "            #frame = cv2.putText(frame, f\"FPS = {fps}\", (20,30), cv2.FONT_HERSHEY_SIMPLEX, 1, (0,0,255), 2)\n",
        "            # append frame to the video file\n",
        "            out.write(frame)\n",
        "            \n",
        "            # the 'q' button is set as the\n",
        "            # quitting button you may use any\n",
        "            # desired button of your choice\n",
        "\n",
        "            if cv2.waitKey(1) & 0xFF == ord('q'):\n",
        "                break\n",
        "\n",
        "        # After the loop release the cap \n",
        "        cap.release()\n",
        "        out.release()\n",
        "\n"
      ],
      "metadata": {
        "id": "Jh9ATKVTWiGA"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "detect_objects_in_videos_directory(net_tiny, test_vids_path, results_yolov3_tiny, size = (416, 416) , \n",
        "                                       score_threshold = 0.3, NMS_threshold = 0.4)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q1rNeVg2b_sm",
        "outputId": "31038ffe-265a-4d7e-bd38-0db8abb1320b"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(360, 640)\n",
            "Error reading frame\n",
            "(360, 640)\n",
            "(640, 360)\n",
            "Error reading frame\n",
            "(640, 360)\n",
            "(720, 1280)\n",
            "Error reading frame\n",
            "(720, 1280)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "detect_objects_in_videos_directory(net, test_vids_path, results_yolov3, size = (416, 416) , \n",
        "                                       score_threshold = 0.5, NMS_threshold = 0.4)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cR69NVaAbqV1",
        "outputId": "80dad9fe-5294-4f23-b867-c66fc8704df5"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(360, 640)\n",
            "Error reading frame\n",
            "(360, 640)\n",
            "(640, 360)\n",
            "Error reading frame\n",
            "(640, 360)\n",
            "(720, 1280)\n",
            "Error reading frame\n",
            "(720, 1280)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def GIF_from_vid(vid_file, gif_file, fps = 20, skip = 2):\n",
        "\n",
        "    \"\"\"\n",
        "    Creates a GIF file from a video file.\n",
        "\n",
        "    Parameters:\n",
        "        vid_file (str): The path to the video file.\n",
        "        gif_file (str): The path to save the generated GIF file.\n",
        "        fps (int, optional): The frames per second to be used in the GIF file. Defaults to 20.\n",
        "        skip (int, optional): The number of frames to skip in the video file. Defaults to 2.\n",
        "\n",
        "    Returns:\n",
        "        None\n",
        "    \"\"\"\n",
        "    \n",
        "    # initialize frame counter\n",
        "    i = 0\n",
        "\n",
        "    cap = cv2.VideoCapture(vid_file)\n",
        "    width  = int(cap.get(3) )  # get `width` \n",
        "    height = int(cap.get(4) )  # get `height` \n",
        "\n",
        "    # Create a writer object to write the frames to a GIF file\n",
        "    writer = imageio.get_writer(gif_file, mode='I',fps=fps)\n",
        "\n",
        "    # Check if the webcam is opened correctly\n",
        "    if not cap.isOpened():\n",
        "        print(\"Error opening video stream or file\")\n",
        "\n",
        "\n",
        "    # Read the video frames\n",
        "    while cap.isOpened():\n",
        "        ret, frame = cap.read()\n",
        "\n",
        "        # If the frame was not read successfully, break the loop\n",
        "        if not ret:\n",
        "            print(\"Error reading frame\")\n",
        "            break\n",
        "\n",
        "        # Increment the frame counter\n",
        "        i+=1\n",
        "\n",
        "        # Skip frames if necessary based on the skip parameter\n",
        "        if( i % skip == 0):\n",
        "            continue\n",
        "\n",
        "        # add current RGB frame to the GIF file\n",
        "        frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
        "        writer.append_data(frame)\n",
        "\n",
        "    # Close the reader and writer objects\n",
        "    writer.close()\n",
        "    cap.release()\n"
      ],
      "metadata": {
        "id": "Ju-DFcoENrcF"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "os.makedirs('gifs/YOLOv3')\n",
        "os.makedirs('gifs/YOLOv3_tiny')"
      ],
      "metadata": {
        "id": "PHINl3jcAv_A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for video_file in os.listdir(results_yolov3):\n",
        "    video_path = os.path.join(results_yolov3, video_file)\n",
        "    save_file = os.path.join('gifs/YOLOv3',video_file[:-4] + '.gif' )\n",
        "    GIF_from_vid(video_path, save_file, fps = 20, skip = 2)"
      ],
      "metadata": {
        "id": "ksOzRb2TAQ2z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for video_file in os.listdir(results_yolov3_tiny):\n",
        "    video_path = os.path.join(results_yolov3_tiny, video_file)\n",
        "    save_file = os.path.join('gifs/YOLOv3_tiny',video_file[:-4] + '.gif' )\n",
        "    GIF_from_vid(video_path, save_file, fps = 20, skip = 2)"
      ],
      "metadata": {
        "id": "eM9jxjIJSSw0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Preparing results for download"
      ],
      "metadata": {
        "id": "xpTXVWxXE8nR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!zip -r results.zip /content/results"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2Tk7jkGhtzIY",
        "outputId": "916e6560-c177-4025-c8f6-1bfea0689c18"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  adding: content/results/ (stored 0%)\n",
            "  adding: content/results/YOLOv3/ (stored 0%)\n",
            "  adding: content/results/YOLOv3/dog video 2.avi (deflated 1%)\n",
            "  adding: content/results/YOLOv3/cat video 2.avi (deflated 2%)\n",
            "  adding: content/results/YOLOv3/traffic.avi (deflated 0%)\n",
            "  adding: content/results/YOLOv3_tiny/ (stored 0%)\n",
            "  adding: content/results/YOLOv3_tiny/dog video 2.avi (deflated 1%)\n",
            "  adding: content/results/YOLOv3_tiny/cat video 2.avi (deflated 2%)\n",
            "  adding: content/results/YOLOv3_tiny/traffic.avi (deflated 0%)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!zip -r gifs.zip /content/gifs"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oRie9Hnm-a82",
        "outputId": "b5b32d75-59da-48cc-a0de-dda05aa8adae"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  adding: content/gifs/ (stored 0%)\n",
            "  adding: content/gifs/YOLOv3/ (stored 0%)\n",
            "  adding: content/gifs/YOLOv3/dog video 2.gif (deflated 0%)\n",
            "  adding: content/gifs/YOLOv3/cat video 2.gif (deflated 0%)\n",
            "  adding: content/gifs/YOLOv3/traffic.gif (deflated 1%)\n",
            "  adding: content/gifs/YOLOv3_tiny/ (stored 0%)\n",
            "  adding: content/gifs/YOLOv3_tiny/dog video 2.gif (deflated 0%)\n",
            "  adding: content/gifs/YOLOv3_tiny/cat video 2.gif (deflated 0%)\n",
            "  adding: content/gifs/YOLOv3_tiny/traffic.gif (deflated 1%)\n"
          ]
        }
      ]
    }
  ]
}